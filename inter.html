<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Copy Python Code Buttons</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      padding: 20px;
    }
    button {
      display: block;
      margin: 10px 0;
      padding: 12px 20px;
      font-size: 16px;
      cursor: pointer;
      width: 300px;
    }
  </style>
</head>
<body>

  <h2>Click a Button to Copy Python Code</h2>

  <button onclick="copyCode1()">P1 Recomm sys </button>
  <button onclick="copyCode2()">P2 Processing Data</button>
  <button onclick="copyCode3()">P3 bubble chart</button>
  <button onclick="copyCode4()">P4 Genome</button>
  <button onclick="copyCode5()">P5 sentinel /MVDI</button>
  <button onclick="copyCode6()">P6 EDA Ecom</button>
  <button onclick="copyCode7()">P7 Sentimental Analysis</button>
  <button onclick="copyCode8()">8 bill board</button>
  <button onclick="copyCode9()">9 Pygal</button>
  <button onclick="copyCode10()">10 Balance sheet</button>
  <button onclick="copyCode11()">11 Mongo</button>

  <script>
    function copyToClipboard(code) {
      navigator.clipboard.writeText(code);
    }

    function copyCode1() {
      copyToClipboard(`
      import pandas as pd
    
    # Load datasets
    movies = pd.read_csv('movies.csv')
    ratings = pd.read_csv('ratings.csv')
    
    # Merge and clean
    df = ratings.merge(movies, on='movieId')
    df.drop(columns=['timestamp', 'genres'], inplace=True)
    
    # Create user-movie matrix
    matrix = df.pivot_table(values='rating', index='movieId', columns='userId').fillna(0)
    
    # Compute user similarity (correlation)
    similar_users = matrix.corr(method='pearson')[2].sort_values(ascending=False).drop(2).head(10)
    
    # Merge top similar users with their rated movies
    similar_df = df[df['userId'].isin(similar_users.index)].copy()
    similar_df['similarity'] = similar_df['userId'].map(similar_users)
    similar_df['score'] = similar_df['similarity'] * similar_df['rating']
    
    # Remove movies already watched by user 2
    watched = df[df['userId'] == 2]['movieId']
    recommended = similar_df[~similar_df['movieId'].isin(watched)]
    
    # Top 10 recommended movie titles
    top_movies = recommended.groupby('title')['score'].mean().sort_values(ascending=False).head(10).reset_index()
    print(top_movies)

      `);
    }

    function copyCode2() {
      copyToClipboard(`
import os
import sys
from pathlib import Path

import pandas as pd
import numpy as np

# Options for pandas
pd.options.display.max_columns = 50
pd.options.display.max_rows = 30
pd.options.display.float_format = '{:,.4f}'.format

# autoreload extension
%load_ext autoreload
%autoreload 2


sys.path.insert(0, str(Path.cwd().parent))

import ast
from PIL import Image
REPO_PATH = Path.cwd()

report_path = '/content/BigData_sizes.csv'
df = pd.read_csv(report_path, converters={'logo_path': str, 'description_html': str,
                                          'logo_rendering': ast.literal_eval,
                                          'arrow_specs': ast.literal_eval
                                          })

df

sort_idx = df.sort_values('size_PB').index
df.loc[sort_idx]

import plotly.graph_objects as go

big_lbls = df.loc[df.size_label.str.contains('EB'), 'size_label']
df.loc[df.size_label.str.contains('EB'), 'size_label'] = ''


layout = {
    'template': "plotly_white",
    'paper_bgcolor': 'rgba(0,0,0,0)',
    'plot_bgcolor': 'rgba(0,0,0,0)',
    'title': {
        'x': 0.5, 'xanchor': 'center'
    },
    'font': dict(
        family="Helvetica",
        size=18,
    ),
    'showlegend': False,
    'autosize': False,
    'width': 1400,
    'height': 720,
    'margin': dict(l=0, r=0, t=0, b=0),
}

# Bubble plot
fig = go.Figure(data=[
    go.Scatter(
        x=df.x, y=df.size_PB,
        #         x0=1,dx=6,
        mode='markers+text',
        marker=dict(
            size=df.area_size,
            color=df.color,
            opacity=[0.7]*(df.shape[0]-1) + [0.4],
            sizemin=12,
            sizemode='area',
            sizeref=2. * df.area_size.max() / (840 ** 2)
        ),
        text=df.size_label.str.replace('yr', 'y'),
        textposition='bottom center',
        textfont=dict(size=14),
    )
]
)

# Big bubbles labels
fig.add_trace(go.Scatter(
    x=[42, 74, 71],
    y=[20000, 3800, 25],
    mode="text",
    text=big_lbls,
    textposition="bottom center",
    textfont=dict(size=[14, 14, 18])
))

# Image annotations
logos_path = REPO_PATH / "/content/"

for v in df[['logo_path', 'logo_rendering']].itertuples():
    if not v.logo_path:
        continue
    src = Image.open(logos_path / v.logo_path)  # logos_path + v.logo_path

    xpos, ypos, xs, ys = v.logo_rendering
    fig.add_layout_image(
        dict(
            source=src,
            xref="paper", yref="paper",
            x=xpos, y=ypos,
            sizex=xs, sizey=ys,
            xanchor="right", yanchor="bottom"
        )
    )


# Text annotations
for v in df[['description_html', 'arrow_specs']].itertuples():
    if not v.arrow_specs:
        continue
    xpos, ypos, xlen, ylen = v.arrow_specs
    fig.add_annotation(
        xref="x", yref="y domain",
        x=xpos, y=ypos,
        ax=xlen, ay=ylen,
        text=v.description_html,
        showarrow=True,
        arrowhead=0,
        font=dict(size=14),
    )

# Layout
fig.update_layout(
    yaxis=dict(
        type="log",
        range=[1, 7.5],
        visible=True,
    ),
    yaxis_title="log size (PB)",
    xaxis_title="source",
    xaxis=dict(
        range=[-4.5, df.x.max()+2],
        visible=True,
        showticklabels=False,
    ),
)

fig.update_layout(layout)

fig.show()
      `);
    }

    function copyCode3() {
      copyToClipboard(`
import pandas as pd
import plotly.graph_objects as go

# Load the dataset
file_path = '/content/experiment.csv'
data = pd.read_csv(file_path)

# Ensure 'area_size' is numeric
data['area_size'] = pd.to_numeric(data['area_size'], errors='coerce')

# Handle missing or NaN values (if any)
data['area_size'] = data['area_size'].fillna(0)  # Replace NaN with 0 or use .dropna()

# Calculate sizeref after ensuring numeric values
sizeref = 2. * data['area_size'].max() / (840 ** 2)

# Prepare the layout for the plot
layout = {
    'template': "plotly_white",
    'paper_bgcolor': 'rgba(0,0,0,0)',
    'plot_bgcolor': 'rgba(0,0,0,0)',
    'title': {
        'text': "Storage Systems Visualization",
        'x': 0.5, 'xanchor': 'center'
    },
    'font': dict(
        family="Helvetica",
        size=18,
    ),
    'showlegend': False,
    'autosize': False,
    'width': 1400,
    'height': 720,
    'margin': dict(l=0, r=0, t=50, b=0),
}

# Create a bubble plot
fig = go.Figure(data=[
    go.Scatter(
        x=data['source'],
        y=data['size_PB'],
        mode='markers+text',
        marker=dict(
            size=data['area_size'],
            color=data['color'],
            opacity=0.7,
            sizemode='area',
            sizeref=sizeref
        ),
        text=data['source'],
        textposition='top center',
        textfont=dict(size=14),
    )
])

# Layout settings
fig.update_layout(
    yaxis=dict(
        type="linear",
        title="Size",
        visible=True,
    ),
    xaxis=dict(
        title="Storage",
        visible=True,
    )
)

fig.update_layout(layout)

# Show the plot
fig.show()
      `);
    }

    function copyCode4() {
      copyToClipboard(`
!pip install biopython
from  Bio import SeqIO
import matplotlib.pyplot as plt
fp="/content/sample.fasta"
for seq_record in SeqIO.parse(fp, "fasta"):
    print(seq_record.id)
    print(repr(seq_record.seq))
    print(len(seq_record))


def calculate_gc_content(sequence, window_size):

    gc_content = []
    for i in range(0, len(sequence) - window_size + 1):
        window = sequence[i:i + window_size]
        gc_count = window.count("G") + window.count("C")
        gc_content.append(gc_count / window_size * 100)
    return gc_content

# Example DNA sequence
dna_sequence = "ATGCGCGTAGCTAGGCTACGCGTACGTAGCGTAGCGTAGCTAGGCTAGCGTACGTAGC"
window_size = 10

# Calculate GC content
gc_values = calculate_gc_content(dna_sequence, window_size)

# Plot GC content
plt.figure(figsize=(10, 5))
plt.plot(range(len(gc_values)), gc_values, marker='o', linestyle='-', color='b')
plt.title(f"GC Content with Window Size {window_size}")
plt.xlabel("Window Position")
plt.ylabel("GC Content (%)")
plt.grid()
plt.show()
      `);
    }

    function copyCode5() {
      copyToClipboard(`
!pip install sentinelhub numpy matplotlib geopandas shapely> /dev/null
from sentinelhub import SHConfig, BBox, CRS, DataCollection, SentinelHubRequest, MimeType
import numpy as np
import matplotlib.pyplot as plt

print('\033[1mSentinel Hub API Configuration:\033[0m')
print('\033[1m====================================\033[0m')
# Configure Sentinel Hub API
config = SHConfig()
config.instance_id = 'fb89a462-8e6b-4d31-8c2b-87f6fe40471b'
config.sh_client_id = '4120319c-6ecc-4a34-8903-ad3a76be7ba3'
config.sh_client_secret = 'S3fZ0K23xmxTZhNDc5Zpwe70m8Wz1gcl'

# Define the area of interest (latitude, longitude) for a specific region
area_of_interest = BBox(bbox=(-74.0, 40.5, -73.8, 40.7), crs=CRS.WGS84)  # Example: NYC

time_interval = ('2024-01-01', '2024-01-10')

evalscript = """
// NDVI calculation
function setup() {
    return {
        input: ["B04", "B08"],
        output: { bands: 1 }
    };
}

function evaluatePixel(sample) {
    let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04);
    return [ndvi];
}
"""

request = SentinelHubRequest(
    evalscript=evalscript,
    input_data=[
        SentinelHubRequest.input_data(
            data_collection=DataCollection.SENTINEL2_L2A,
            time_interval=time_interval
        )
    ],
    responses=[
        SentinelHubRequest.output_response('default', MimeType.TIFF)
    ],
    bbox=area_of_interest,
    size=(512, 512),
    config=config
)

# Get data (list of arrays)
response = request.get_data()

# Assign the first (and likely only) array to ndvi_data
ndvi_data = response[0]

# Convert to float and clip
ndvi_data = ndvi_data.astype(np.float32)
ndvi_data = np.clip(ndvi_data, -1, 1)

# If the array has extra dimensions (e.g. shape [512, 512, 1]), squeeze them
if ndvi_data.ndim == 3 and ndvi_data.shape[-1] == 1:
    ndvi_data = ndvi_data.squeeze(-1)

# Plot NDVI
plt.figure(figsize=(10, 8))
plt.title("NDVI Analysis")
plt.imshow(ndvi_data, cmap='YlGn')
plt.colorbar(label="NDVI Value")
plt.show()
      `);
    }

    function copyCode6() {
      copyToClipboard(`
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re

# Load dataset
df = pd.read_csv("/content/Womens Clothing E-Commerce Reviews.csv")

# Drop rows with missing reviews
df = df.dropna(subset=['Review Text'])

# Function to clean text
def clean_text(text):
    text = text.lower()  # Convert to lowercase
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Remove special characters
    text = re.sub(r'\s+', ' ', text).strip()  # Remove extra spaces
    return text

# Apply text cleaning
df['Cleaned Review'] = df['Review Text'].apply(clean_text)

# Plot rating distribution
plt.figure(figsize=(8,5))
sns.countplot(x=df['Rating'], palette='viridis')
plt.title('Review Rating Distribution')
plt.xlabel('Rating')
plt.ylabel('Count')

plt.show()
# Pie chart for recommended vs. not recommended
plt.figure(figsize=(6,6))
df['Recommended IND'].value_counts().plot.pie(autopct='%1.1f%%', colors=['lightblue', 'orange'])
plt.title('Recommendation Distribution')
plt.ylabel('')
plt.show()

# Boxplot for age distribution by rating
plt.figure(figsize=(10,6))
sns.boxplot(x='Rating', y='Age', data=df, palette='coolwarm')
plt.title('Age Distribution by Rating')
plt.xlabel('Rating')
plt.ylabel('Age')
plt.show()

# Bar chart for top 10 most reviewed clothing items
plt.figure(figsize=(12,6))
top_products = df['Clothing ID'].value_counts().nlargest(10)
top_products.plot(kind='bar', color='teal')
plt.title('Top 10 Most Reviewed Clothing Items')
plt.xlabel('Clothing ID')
plt.ylabel('Number of Reviews')
plt.show()

      `);
    }

    function copyCode7() {
      copyToClipboard(`
!pip install wordcloud seaborn nltk > /dev/null
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import nltk
from nltk.corpus import stopwords
from collections import Counter
import re
from keras.datasets import imdb

nltk.download('stopwords')
nltk.download('punkt')
stop_words = set(stopwords.words('english'))

def load_and_clean_data(num_words=10000):
    (train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=num_words)
    word_index = imdb.get_word_index()
    reverse_word_index = {value: key for (key, value) in word_index.items()}
    decode_review = lambda seq: " ".join([reverse_word_index.get(i - 3, "?") for i in seq if i >= 3])
    reviews = [decode_review(seq) for seq in train_data + test_data]
    labels = train_labels + test_labels
    sentiments = ['positive' if label == 1 else 'negative' for label in labels]
    df = pd.DataFrame({'review': reviews, 'sentiment': sentiments})
    df.drop_duplicates(inplace=True)
    df.dropna(inplace=True)
    return df

df = load_and_clean_data(num_words=10000)
print(df.head())
print("\nMissing Values:\n", df.isnull().sum())
print("\nSentiment Distribution:\n", df["sentiment"].value_counts())

def clean_text(text):
    text = re.sub(r'<.*?>|[^a-zA-Z ]', '', text.lower())
    return ' '.join([word for word in text.split() if word not in stop_words])

df['clean_review'] = df['review'].astype(str).apply(clean_text)

# Sentiment Analysis Visualization
plt.figure(figsize=(8, 5))
sns.barplot(x=df['sentiment'].value_counts().index, y=df['sentiment'].value_counts().values, palette='coolwarm')
plt.title("Sentiment Distribution in IMDb Reviews")
plt.xlabel("Sentiment")
plt.ylabel("Count")
plt.show()

# Word Frequency in Positive vs Negative Reviews
positive_words = ' '.join(df[df['sentiment'] == 'positive']['clean_review']).split()
negative_words = ' '.join(df[df['sentiment'] == 'negative']['clean_review']).split()
positive_word_counts = Counter(positive_words).most_common(20)
negative_word_counts = Counter(negative_words).most_common(20)

positive_df = pd.DataFrame(positive_word_counts, columns=['Word', 'Count'])
negative_df = pd.DataFrame(negative_word_counts, columns=['Word', 'Count'])

# Plot most common words in positive reviews
plt.figure(figsize=(8, 5))
sns.barplot(x='Count', y='Word', data=positive_df, palette='coolwarm')
plt.title("Top 20 Words in Positive Reviews")
plt.show()

# Plot most common words in negative reviews
plt.figure(figsize=(8, 5))
sns.barplot(x='Count', y='Word', data=negative_df, palette='coolwarm')
plt.title("Top 20 Words in Negative Reviews")
plt.show()
      `);
    }

    function copyCode8() {
      copyToClipboard(`
#R
pick_bill_song <- function(songs,num_songs){

  shuffle_songs <-sample(songs)
  bill_songs <-head(shuffle_songs,num_songs)
  return(bill_songs)
}
all_songs <-c("song 1","song 2","song 3","song 4","song5","song6","song 7","song8","song 9","song 10"
)
num_bill_song <-4

bill_songs <- pick_bill_song(all_songs,num_bill_song)
cat("BILLBOARD SONGS ARE :\n")
for (song in bill_songs){
  cat(song,"\n")
}

#Pyhton
import pandas as pd

data = {
    'content_id': [1, 2, 3, 4, 5, 6],
    'title': ['Tiger 3', 'Arijit Singh Live in Concert', 'Super Bowl Ad', 'Bajrangi Bhaijaan', 'The Voice Finale', 'Coca-Cola Ad'],
    'category': ['Entertainment', 'Music', 'Advertisement', 'Entertainment', 'TV Show', 'Advertisement'],
    'views': [95000, 80000, 70000, 85000, 45000, 90000]
}

df = pd.DataFrame(data)

billboard_data = df[(df['category'] == 'Entertainment') & (df['views'] > 50000)]

# Display the filtered content
print("Billboard Content:")
print(billboard_data)
      `);
    }

    function copyCode9() {
      copyToClipboard(`
!pip install pygal pyspark  > /dev/null
import pygal
import random

regions = [f'Region {i}' for i in range(1, 11)]
months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

# Generate random sales data for 10 regions over 12 months
sales_data = {region: [random.randint(1000, 10000) for _ in months] for region in regions}

bar_chart = pygal.Bar(title='Total Sales Across 10 Regions (Yearly)')
for region, sales in sales_data.items():
    bar_chart.add(region, sum(sales))  # Summing up monthly sales per region

# Save as SVG
bar_chart.render_to_file('total_sales_regions.svg')

top_regions = sorted(sales_data.items(), key=lambda x: sum(x[1]), reverse=True)[:3]

line_chart = pygal.Line(title='Monthly Sales Trends for Top 3 Regions')
line_chart.x_labels = months

# Add monthly sales data for top 3 regions
for region, sales in top_regions:
    line_chart.add(region, sales)


line_chart.render_to_file('top_regions_trends.svg')
      `);
    }

    function copyCode10() {
      copyToClipboard(`
balance_data = pd.DataFrame({
    'Date': ['2024-01-01', '2024-01-05', '2024-01-10', '2024-01-12',
             '2024-01-15', '2024-01-20', '2024-01-25'],
    'Account': ['Sales', 'Purchase', 'Sales', 'Expense', 'Sales', 'Purchase', 'Salary'],
    'Amount': [15000, -12000, 20000, -5000, 0, -8000, 10000],
    'Status': ['Valid', 'Valid', 'Invalid', 'Valid', 'Invalid', 'Valid', 'Valid']
})

valid_data = balance_data[(balance_data['Status'] == 'Valid') & (balance_data['Amount'] != 0)]


valid_data.to_csv('cleaned_balance_sheet.csv', index=False)

print("Valid balance sheet data processed and saved to 'cleaned_balance_sheet.csv'.")
      `);
    }

    function copyCode11() {
      copyToClipboard(`
!pip install pymongo matplotlib > /dev/null
import matplotlib.pyplot as plt
from pymongo import MongoClient
class MongoDBClient:
    def __init__(self, uri, db_name):
        self.client = MongoClient(uri)
        self.db = self.client[db_name]
        self.status_message = f"Connected to {db_name}"
    def retrieve_documents(self, collection_name, limit=0):
        """Retrieve documents from the specified collection."""
        return list(self.db[collection_name].find(limit=limit))
ATLAS_URI = "mongodb+srv://surabhisalunke02:C3g8b2m8#@cluster0.w1xhx.mongodb.net/?retryWrites=true&w=majority"
DB_NAME = 'sample_mflix'
COLLECTION_NAME = 'embedded_movies'
client = MongoDBClient(ATLAS_URI, DB_NAME)
docs = client.retrieve_documents(COLLECTION_NAME, limit=5)
total_movies = client.db[COLLECTION_NAME].count_documents({})
output_message = (
    f"{client.status_message}\n"
    f"Total Movies: {total_movies}\n"
    f"Retrieved: {len(docs)} Movies\n\n"
    + "\n\n".join(
        [f'Title: {doc.get("title", "N/A")}\n'
         f'Year: {doc.get("year", "N/A")}\n'
         f'Plot: {doc.get("plot", "N/A")}\n'
         for doc in docs] ))
plt.figure(figsize=(10, 6))
plt.text(0.1, 0.5, output_message, fontsize=12, ha='left', va='center', wrap=True)
plt.axis('off')
plt.title("Movie Information", fontsize=16)

      `);
    }
  </script>

</body>
</html>
