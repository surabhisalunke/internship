<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title></title>
</head>
<body>
    <button onclick="copyText(`import tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Step 1: Prepare the dataset\nemails = [\n    \"Buy cheap watches! Free shipping!\", \n    \"Meeting for lunch today?\", \n    \"Claim your prize! You've won $1,000,000!\", \n    \"Important meeting at 3 PM.\"\n]\nlabels = [1, 0, 1, 0]\n\n# Step 2: Tokenize and pad the text data\ntokenizer = Tokenizer(num_words=1000, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(emails)\nX_padded = pad_sequences(tokenizer.texts_to_sequences(emails), maxlen=50, padding=\"post\")\n\n# Step 3: Define the model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=1000, output_dim=16),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Step 4: Train the model\nmodel.fit(X_padded, np.array(labels), epochs=10)\n\n# Step 5: Predict on a sample email (replace with a file read if needed)\nsample_email = [\"Congratulations! You've won a lottery prize!\"]\nsample_padded = pad_sequences(tokenizer.texts_to_sequences(sample_email), maxlen=50, padding=\"post\")\n\n# Step 6: Classify the email\nprediction = model.predict(sample_padded)\nprint(\"SPAM\" if prediction > 0.5 else \"NOT SPAM\")`)">Spam Classifier</button>

    <button onclick="copyText(`# Web Crawling and Indexing\n# Develop a web crawler to fetch and index web pages. Handle challenges such as robots.txt, dynamic content, and crawling delays.\n\nimport nltk\nnltk.download('stopwords')\nnltk.download('punkt')\nimport requests\nfrom bs4 import BeautifulSoup\nfrom urllib.parse import urljoin\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport re\n\nprint(\"KSMSCIT028 Surabhi A Salunke\")\nprint(\"---------------------------\")\n\n# Seed URLs\nseed_urls = ['https://indianexpress.com/section/india/', 'https://www.indianretailer.com/restaurant/']\n\n# Keywords to focus on\nkeywords = ['restaurant', 'food', 'local']\n\n# Stop words to filter out common words\nstop_words = set(stopwords.words('english'))\n\n# Visited URLs\nvisited = set()\n\ndef is_relevant(content, keywords):\n    # Check if the content is relevant based on the keywords.\n    words = word_tokenize(content.lower())\n    words = [w for w in words if w.isalnum() and w not in stop_words]\n    return any(keyword in words for keyword in keywords)\n\ndef crawl(url):\n    # Crawl a single webpage.\n    try:\n        response = requests.get(url)\n        soup = BeautifulSoup(response.content, 'html.parser')\n        text = soup.get_text()\n\n        # Check if the content is relevant\n        if is_relevant(text, keywords):\n            print(f\"Relevant content found at: {url}\")\n            # Here you could save the content to a file or database\n\n            # Extract links and follow them\n            for link in soup.find_all('a', href=True):\n                new_url = urljoin(url, link['href'])\n                if new_url not in visited and re.match(r'^https?://', new_url):\n                    visited.add(new_url)\n                    crawl(new_url)\n    except requests.exceptions.RequestException as e:\n        print(f\"Error crawling {url}: {e}\")\n\n# Start crawling from the seed URLs\nfor url in seed_urls:\n    if url not in visited:\n        visited.add(url)\n        crawl(url)`)">Web Crawling and Indexing</button>

    <script>
        function copyText(text) {
            // Create a temporary textarea element to hold the text
            const textarea = document.createElement('textarea');
            textarea.value = text;
            document.body.appendChild(textarea);

            // Select and copy the text
            textarea.select();
            document.execCommand('copy');

            // Remove the temporary textarea element
            document.body.removeChild(textarea);
        }
    </script>
</body>
</html>
